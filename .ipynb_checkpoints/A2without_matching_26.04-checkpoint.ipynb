{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /Users/victoria/anaconda3/lib/python3.11/site-packages (0.20.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T14:14:11.957887Z",
     "start_time": "2024-04-10T14:13:49.265971Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/data_cleaned.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Загрузка исходных данных из файла parquet\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m data_cleaned \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/data_cleaned.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m data_cleaned[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mГод\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(data_cleaned[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mГод\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m columns_to_drop \u001b[38;5;241m=\u001b[39m [       \n\u001b[1;32m     10\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Выручка, RUB\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Краткосрочные обязательства, RUB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Кредиторская задолженность, RUB\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Нераспределенная прибыль (непокрытый убыток), RUB\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Себестоимость продаж, RUB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Собственный оборотный капитал, RUB\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Активы  всего, RUB\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parquet.py:509\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    507\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    510\u001b[0m     path,\n\u001b[1;32m    511\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m    512\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    513\u001b[0m     use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[1;32m    514\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    516\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parquet.py:220\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, use_nullable_dtypes, dtype_backend, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    218\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m path_or_handle, handles, kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    221\u001b[0m     path,\n\u001b[1;32m    222\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    223\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    224\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m )\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    228\u001b[0m         path_or_handle, columns\u001b[38;5;241m=\u001b[39mcolumns, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    229\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parquet.py:110\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    100\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     handles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m    111\u001b[0m         path_or_handle, mode, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/data_cleaned.parquet'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка исходных данных из файла parquet\n",
    "data_cleaned = pd.read_parquet('data/data_cleaned.parquet')\n",
    "data_cleaned['Год'] = pd.to_numeric(data_cleaned['Год'], errors='coerce')\n",
    "\n",
    "columns_to_drop = [       \n",
    "  ' Выручка, RUB',\n",
    "' Краткосрочные обязательства, RUB', ' Кредиторская задолженность, RUB',\n",
    "' Нераспределенная прибыль (непокрытый убыток), RUB',\n",
    "' Себестоимость продаж, RUB', ' Собственный оборотный капитал, RUB',' Активы  всего, RUB'\n",
    "]\n",
    "data_cleaned = data_cleaned.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "# Список столбцов, для которых нужно рассчитать изменения в процентах за последний год\n",
    "columns_to_calculate = [' Cooтношение дебиторской задолженности к активам компании, %',\n",
    "       ' Доля рабочего капитала в активах компании, %',\n",
    "       ' Коэффициент абсолютной ликвидности, %',\n",
    "       ' Коэффициент быстрой ликвидности, %',\n",
    "       ' Коэффициент обеспеченности собственными оборотными средствами, %',\n",
    "       ' Коэффициент оборачиваемости совокупных активов, %',\n",
    "       ' Коэффициент соотношения заемных и собственных средств, %',\n",
    "       ' Коэффициент текущей ликвидности, %',\n",
    "       ' Период оборота активов, дни', ' Период оборота запасов, дни',\n",
    "       ' Период оборота основных средств, дни',\n",
    "       ' Период погашения дебиторской задолженности, дни',\n",
    "       ' Период погашения кредиторской задолженности, дни',\n",
    "       ' Рентабельность активов (ROA), %', ' Рентабельность затрат, %',\n",
    "       ' Рентабельность капитала (ROE), %', ' Рентабельность продаж, %',\n",
    "       ' Соотношение чистого долга к капиталу, %']\n",
    "\n",
    "# Выбор последних двух годов для каждой компании\n",
    "last_years_data = data_cleaned.groupby('Наименование').apply(lambda x: x.nlargest(2, 'Год')).reset_index(drop=True)\n",
    "\n",
    "def calculate_percentage_change(df, columns, years):\n",
    "    if len(df) < years:\n",
    "        return pd.Series([float('NaN')] * len(columns), index=columns)\n",
    "    changes = (df.iloc[years-1][columns] - df.iloc[0][columns]) / df.iloc[0][columns] * 100\n",
    "    return changes\n",
    "\n",
    "# Вычисление изменений в процентах за последние 2 и 3 года для указанных столбцов\n",
    "last_2_years_changes = data_cleaned.groupby('Наименование').apply(calculate_percentage_change, columns=columns_to_calculate, years=2)\n",
    "last_3_years_changes = data_cleaned.groupby('Наименование').apply(calculate_percentage_change, columns=columns_to_calculate, years=3)\n",
    "last_4_years_changes = data_cleaned.groupby('Наименование').apply(calculate_percentage_change, columns=columns_to_calculate, years=4)\n",
    "\n",
    "# Замена пропусков на нули\n",
    "last_2_years_changes = last_2_years_changes.fillna(0)\n",
    "last_3_years_changes = last_3_years_changes.fillna(0)\n",
    "last_4_years_changes = last_4_years_changes.fillna(0)\n",
    "# Переименование столбцов\n",
    "last_2_years_changes.columns = [col + '_change_last_2_years' for col in last_2_years_changes.columns]\n",
    "last_3_years_changes.columns = [col + '_change_last_3_years' for col in last_3_years_changes.columns]\n",
    "last_4_years_changes.columns = [col + '_change_last_4_years' for col in last_4_years_changes.columns]\n",
    "\n",
    "\n",
    "# Объединение информации об изменениях с исходным датафреймом\n",
    "data_cleaned = pd.merge(data_cleaned, last_2_years_changes, on='Наименование', how='left')\n",
    "data_cleaned = pd.merge(data_cleaned, last_3_years_changes, on='Наименование', how='left')\n",
    "data_cleaned = pd.merge(data_cleaned, last_4_years_changes, on='Наименование', how='left')\n",
    "# Вывод результата\n",
    "data_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T14:14:12.001405Z",
     "start_time": "2024-04-10T14:14:11.958885Z"
    }
   },
   "outputs": [],
   "source": [
    "# Фильтруем данные по категориальной переменной\n",
    "bankrupt_data = data_cleaned[data_cleaned['Категориальная переменная'] == True]\n",
    "no_bankrupt_data = data_cleaned[data_cleaned['Категориальная переменная'] == False]\n",
    "\n",
    "# Приводим столбец 'Год' в тип int для компаний\n",
    "no_bankrupt_data['Год'] = no_bankrupt_data['Год'].astype(int)\n",
    "bankrupt_data['Год'] = bankrupt_data['Год'].astype(int)\n",
    "no_bankrupt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T14:14:12.029963Z",
     "start_time": "2024-04-10T14:14:12.002912Z"
    }
   },
   "outputs": [],
   "source": [
    "# Вычисляем год иска для компаний, которые банкроты\n",
    "bankrupt_data['Год иска'] = bankrupt_data['Дата иска'].apply(lambda x: x.year - 2 if x.month > 3 else x.year - 1)\n",
    "\n",
    "# Фильтруем банкроты по году\n",
    "filtered_data = bankrupt_data[bankrupt_data['Год'] == bankrupt_data['Год иска']]\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T14:14:12.072734Z",
     "start_time": "2024-04-10T14:14:12.030965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Сортировка данных по столбцам \"наименование\" и \"год\"\n",
    "sorted_data = no_bankrupt_data.sort_values(by=['Наименование', 'Год'])\n",
    "\n",
    "# Группировка данных по столбцу \"наименование\" и выбор последней строки из каждой группы\n",
    "last_year_data = sorted_data.groupby('Наименование').tail(1)\n",
    "last_year_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T14:14:22.046233Z",
     "start_time": "2024-04-10T14:14:12.073742Z"
    }
   },
   "outputs": [],
   "source": [
    "no_matched_data = pd.concat([last_year_data, filtered_data], ignore_index=True)\n",
    "\n",
    "no_matched_data.to_parquet('data/no_matched_data.parquet')\n",
    "\n",
    "# Save the matching_data DataFrame as an Excel file\n",
    "no_matched_data.to_excel('data/no_matched_data.xlsx', index=False)\n",
    "no_matched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T14:14:22.072326Z",
     "start_time": "2024-04-10T14:14:22.047233Z"
    }
   },
   "outputs": [],
   "source": [
    "y = no_matched_data['Категориальная переменная']\n",
    "\n",
    "X = no_matched_data.select_dtypes(exclude=['object'])\n",
    "\n",
    "X = X.drop(columns=['index','Регистрационный номер','Код налогоплательщика','Категориальная переменная','Дата иска','Год иска'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T14:14:22.087364Z",
     "start_time": "2024-04-10T14:14:22.073336Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Разделите данные на тренировочный и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
    "\n",
    "# ДОРАБОТКА - валидационная выборка для ROC кривой\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=42, stratify=y_train)\n",
    "\n",
    "# Check for infinite or NaN values in X_train and replace them with a suitable value\n",
    "X_train.replace([np.inf, -np.inf, np.nan], 0, inplace=True)\n",
    "\n",
    "# Check for infinite or NaN values in X_val and replace them with a suitable value\n",
    "X_val.replace([np.inf, -np.inf, np.nan], 0, inplace=True)\n",
    "\n",
    "# Check for infinite or NaN values in X_test and replace them with a suitable value\n",
    "X_test.replace([np.inf, -np.inf, np.nan], 0, inplace=True)\n",
    "\n",
    "X_train.columns = [\"\".join(c if c.isalnum() or c in {'_', '.'} else '_' for c in str(x)) for x in X_train.columns]\n",
    "X_val.columns = [\"\".join(c if c.isalnum() or c in {'_', '.'} else '_' for c in str(x)) for x in X_val.columns]\n",
    "X_test.columns = [\"\".join(c if c.isalnum() or c in {'_', '.'} else '_' for c in str(x)) for x in X_test.columns]\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-09T21:48:14.081023Z"
    }
   },
   "outputs": [],
   "source": [
    "# Сохраняем данные в формате parquet\n",
    "X_train.to_parquet('data/X_train.parquet', index=False)\n",
    "X_val.to_parquet('data/X_val.parquet', index=False)\n",
    "X_test.to_parquet('data/X_test.parquet', index=False)\n",
    "y_train.to_frame().to_parquet('data/y_train.parquet', index=False)\n",
    "y_val.to_frame().to_parquet('data/y_val.parquet', index=False)\n",
    "y_test.to_frame().to_parquet('data/y_test.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T14:17:12.400727Z",
     "start_time": "2024-04-10T14:17:12.393627Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, classification_report\n",
    "from math import sqrt\n",
    "\n",
    "def calculate_regression_metrics(y_true, y_pred):\n",
    "    # Вычисление MAE\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    print(f\"MAE: {mae}\")\n",
    "\n",
    "    # Вычисление MSE и RMSE\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "\n",
    "    # # Вычисление MAPE\n",
    "    # mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    # print(f\"MAPE: {mape}%\")\n",
    "\n",
    "    # Вычисление R^2\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"R^2: {r2}\")\n",
    "\n",
    "def calculate_classification_metrics(y_true, y_pred):\n",
    "    # Округление предсказаний\n",
    "    y_pred_rounded = [round(value) for value in y_pred]\n",
    "\n",
    "    # Вычисление метрик классификации\n",
    "    classification_metrics = classification_report(y_true, y_pred_rounded)\n",
    "    print(classification_metrics)\n",
    "\n",
    "# Вызов функции метрик для задачи регрессии с LGBM\n",
    "\n",
    "# Предположим, что preds_class - предсказанные вероятности или классы модели классификации\n",
    "# преобразуем вероятности в классы, если это необходимо, прежде чем использовать функцию calculate_classification_metrics()\n",
    "# примерно так: \n",
    "# затем вызываем функцию метрик для задачи классификации (если у вас задача классификации)\n",
    "#print(\"Metrics for LightGBM (Classification):\")\n",
    "#\n",
    "\n",
    "# Замечание: Удалите или закомментируйте вызов функции для задачи классификации, если у вас задача регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ДОРАБОТКА 1 - ФУНКЦИЯ ПОСТРОЕНИЯ ROC кривой и вывод AUC score\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def build_roc_curve(y_test, preds):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    auc_score = roc_auc_score(y_test, preds)\n",
    "    print(\"AUC: \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T14:17:44.389592Z",
     "start_time": "2024-04-10T14:17:40.428691Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Предполагается, что X и y - это ваш датасет\n",
    "# X = ... # Ваши входные данные (features)\n",
    "# y = ... # Ваша целевая переменная (target)\n",
    "zxc = \"_auto\"\n",
    "# Загружаем данные из формата parquet\n",
    "# X_train = pd.read_parquet(f'data/X_train.parquet{zxc}')\n",
    "# X_val = pd.read_parquet(f'data/X_val.parquet{zxc}')\n",
    "# X_test = pd.read_parquet(f'data/X_test.parquet{zxc}')\n",
    "# y_train = pd.read_parquet(f'data/y_train.parquet{zxc}')\n",
    "# y_val = pd.read_parquet(f'data/y_val.parquet{zxc}')\n",
    "# y_test = pd.read_parquet(f'data/y_test.parquet{zxc}')\n",
    "# Задаем гиперпараметры для LightGBM\n",
    "params = {\n",
    "    \"boosting\": \"dart\",\n",
    "    \"lambda_l1\": 0.6908619234998079,\n",
    "    \"lambda_l2\": 0.3955923595617765,\n",
    "    \"bagging_fraction\": 0.8517327079270671,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"num_leaves\": 40,\n",
    "    \"max_depth\": 9,\n",
    "    \"learning_rate\": 0.04650198552323694,\n",
    "    \"max_bin\": 700,\n",
    "    \"num_iterations\": 400,\n",
    "}\n",
    "\n",
    "# # Разделение данных на тренировочный и тестовый наборы\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model_lgb = lgb.LGBMClassifier(**params)\n",
    "# Обучение модели\n",
    "model_lgb.fit(X_train, y_train)\n",
    "# Предсказание для тестового набора данных\n",
    "lgbm_preds_bin = model_lgb.predict(X_val)\n",
    "print(\"Metrics for LightGBM (Classifier):\") # ДОРАБОТКА: исправил название в тексте на Classifier\n",
    "calculate_classification_metrics(y_val, lgbm_preds_bin) # Здесь тоже зачем-то вызывались метрики регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ДОРАБОТКА 1.1 - эксперимент на LGBM\n",
    "# результат странный, наверное из-за специфики LGBM - upd: проблема была в регрессии, исправили\n",
    "lgbm_preds = model_lgb.predict_proba(X_val)[:, 1]\n",
    "build_roc_curve(y_val, lgbm_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_tree(model_lgb, tree_index=0, figsize=(15,10), show_info=['split_gain', 'internal_value', 'internal_count', 'leaf_count'])\n",
    "plt.savefig('lgbm_tree.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T14:20:48.843742Z",
     "start_time": "2024-04-10T14:20:47.502958Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "zxc = \"_auto\"\n",
    "# Загружаем данные из формата parquet\n",
    "# X_train = pd.read_parquet(f'data/X_train.parquet{zxc}')\n",
    "# X_test = pd.read_parquet(f'data/X_test.parquet{zxc}')\n",
    "# y_train = pd.read_parquet(f'data/y_train.parquet{zxc}')\n",
    "# y_test = pd.read_parquet(f'data/y_test.parquet{zxc}')\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    \"max_depth\": 11,\n",
    "    \"n_estimators\": 1500,\n",
    "    \"learning_rate\": 0.056505476002963344,\n",
    "    \"subsample\": 0.7,\n",
    "    \"gamma\": 0.1493988264994933,\n",
    "    \"min_child_weight\": 0.14882816532567922,\n",
    "    \"max_delta_step\": 0.4260247335309186,\n",
    "    \"colsample_bytree\": 0.9068581911881414,\n",
    "    \"reg_alpha\": 0.6330159374879993,\n",
    "    \"reg_lambda\": 0.8476194476619723,\n",
    "    \"scale_pos_weight\": 0.9468520576013162\n",
    "}\n",
    "model_xgb = xgb.XGBClassifier()\n",
    "model_xgb.fit(X_train, y_train)\n",
    "# Предсказание для тестового набора данных\n",
    "xgb_preds_bin = model_xgb.predict(X_val)\n",
    "print(\"Metrics for XGBOOST (Classification):\")\n",
    "\n",
    "calculate_classification_metrics(y_val, xgb_preds_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ДОРАБОТКА 1.2 ROC AUC для XGB\n",
    "\n",
    "val_preds_xgb = model_xgb.predict_proba(X_val)[:, 1]\n",
    "build_roc_curve(y_val, val_preds_xgb)\n",
    "\n",
    "# Далее для любой другой регрессии также можно вызвать эту функцию, передав y_val и результат модели на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_tree(model_xgb, num_trees=0, rankdir='LR')\n",
    "plt.savefig('xgb_tree.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Получаем вероятности класса 1 (положительный класс)\n",
    "val_preds_xgb = model_xgb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Инициализируем списки для хранения значений sensitivity и specificity\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "\n",
    "# Итерируемся по различным порогам от 0 до 1\n",
    "thresholds = np.linspace(0, 1, 500) # увеличили точность, но можно делать по реальным порогам\n",
    "for cutoff in thresholds:\n",
    "    # Получаем предсказанные классы по текущему порогу\n",
    "    predicted_classes = (val_preds_xgb >= cutoff).astype(int)\n",
    "    \n",
    "    # Считаем матрицу ошибок\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, predicted_classes).ravel()\n",
    "    \n",
    "    # Рассчитываем sensitivity и specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    # Добавляем в список\n",
    "    sensitivities.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "\n",
    "\n",
    "# Строим график\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, sensitivities, label=\"XGB Sensitivity\")\n",
    "plt.plot(thresholds, specificities, label=\"XGB Specificity\")\n",
    "plt.title(\"XGB Sensitivity and Specificity vs. Probability Cutoff\")\n",
    "plt.xlabel(\"Probability Cutoff Threshold\")\n",
    "plt.ylabel(\"Sensitivity/Specificity\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Определение оптимального порога как точки пересечения\n",
    "# Находим индекс минимальной разницы между sensitivity и specificity\n",
    "index_of_optimal_threshold = np.argmin(np.abs(np.array(sensitivities) - np.array(specificities)))\n",
    "optimal_threshold_xgb = thresholds[index_of_optimal_threshold]\n",
    "print(f\"Optimal Threshold: {optimal_threshold_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем вероятности класса 1 (положительный класс)\n",
    "val_preds_lgb = model_lgb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Инициализируем списки для хранения значений sensitivity и specificity\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "\n",
    "# Итерируемся по различным порогам от 0 до 1\n",
    "thresholds = np.linspace(0, 1, 500) # увеличили точность, но можно делать по реальным порогам\n",
    "for cutoff in thresholds:\n",
    "    # Получаем предсказанные классы по текущему порогу\n",
    "    predicted_classes = (val_preds_lgb >= cutoff).astype(int)\n",
    "    \n",
    "    # Считаем матрицу ошибок\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, predicted_classes).ravel()\n",
    "    \n",
    "    # Рассчитываем sensitivity и specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    # Добавляем в список\n",
    "    sensitivities.append(sensitivity)\n",
    "    specificities.append(specificity)\n",
    "\n",
    "\n",
    "# Строим график\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, sensitivities, label=\"LGBM Sensitivity\")\n",
    "plt.plot(thresholds, specificities, label=\"LGBM Specificity\")\n",
    "plt.title(\"LGBM Sensitivity and Specificity vs. Probability Cutoff\")\n",
    "plt.xlabel(\"Probability Cutoff Threshold\")\n",
    "plt.ylabel(\"Sensitivity/Specificity\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Определение оптимального порога как точки пересечения\n",
    "# Находим индекс минимальной разницы между sensitivity и specificity\n",
    "index_of_optimal_threshold = np.argmin(np.abs(np.array(sensitivities) - np.array(specificities)))\n",
    "optimal_threshold_lgb = thresholds[index_of_optimal_threshold]\n",
    "print(f\"Optimal Threshold: {optimal_threshold_lgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = (model_xgb.predict_proba(X_test)[:,1] >= optimal_threshold_xgb).astype(int)\n",
    "calculate_classification_metrics(y_test, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = (model_lgb.predict_proba(X_test)[:,1] >= optimal_threshold_lgb).astype(int)\n",
    "calculate_classification_metrics(y_test, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.predict_proba(X_test)[0] # вероятности классов у 1 строки\n",
    "# вероятность 0 (не банкротства), вероятность 1 (банкротства)\n",
    "# [0.9969689, 0.0030311] - список двух вероятностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb.predict_proba(X_test)[0][1]\n",
    "# берём только вероятность 1 (банкротства)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ДОРАБОТКА 2 - модель Альтмана\n",
    "\n",
    "params_public = (1.2,  1.4, 3.3, 0.6, 1.0)\n",
    "params_private = (0.717, 0.847, 3.107, 0.42, 0.995)\n",
    "\n",
    "def altman_z_score(row, P = None):\n",
    "    \n",
    "    if not P:\n",
    "        P = (1.2,  1.4, 3.3, 0.6, 1.0)\n",
    "\n",
    "    X1 = row[' Доля рабочего капитала в активах компании, %']/100\n",
    "    X2 = row[' Нераспределенная прибыль (непокрытый убыток), RUB'] / row[' Активы  всего, RUB']\n",
    "    X3 = (row[' Выручка, RUB'] - row[' Себестоимость продаж, RUB']) / row[' Активы  всего, RUB']\n",
    "    X4 = row[' Собственный оборотный капитал, RUB'] / (row[' Краткосрочные обязательства, RUB'] + row[' Кредиторская задолженность, RUB'])\n",
    "    X5 = row[' Выручка, RUB'] / row[' Активы  всего, RUB']\n",
    "    # X5 - ' Коэффициент оборачиваемости совокупных активов, %'/100\n",
    "\n",
    "    Z = P[0] * X1 + P[1] * X2 + P[2] * X3 + P[3] * X4 + P[4] * X5\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns[:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# переименование столбцов обратно в исходные\n",
    "\n",
    "column_mapping = {\n",
    "    'Год': 'Год',\n",
    "    '_Cooтношение_дебиторской_задолженности_к_активам_компании___': ' Cooтношение дебиторской задолженности к активам компании, %',\n",
    "    '_Доля_рабочего_капитала_в_активах_компании___': ' Доля рабочего капитала в активах компании, %',\n",
    "    '_Коэффициент_абсолютной_ликвидности___': ' Коэффициент абсолютной ликвидности, %',\n",
    "    '_Коэффициент_быстрой_ликвидности___': ' Коэффициент быстрой ликвидности, %',\n",
    "    '_Коэффициент_обеспеченности_собственными_оборотными_средствами___': ' Коэффициент обеспеченности собственными оборотными средствами, %',\n",
    "    '_Коэффициент_оборачиваемости_совокупных_активов___': ' Коэффициент оборачиваемости совокупных активов, %',\n",
    "    '_Коэффициент_соотношения_заемных_и_собственных_средств___': ' Коэффициент соотношения заемных и собственных средств, %',\n",
    "    '_Коэффициент_текущей_ликвидности___': ' Коэффициент текущей ликвидности, %',\n",
    "    '_Период_оборота_активов__дни': ' Период оборота активов, дни',\n",
    "    '_Период_оборота_запасов__дни': ' Период оборота запасов, дни',\n",
    "    '_Период_оборота_основных_средств__дни': ' Период оборота основных средств, дни',\n",
    "    '_Период_погашения_дебиторской_задолженности__дни': ' Период погашения дебиторской задолженности, дни',\n",
    "    '_Период_погашения_кредиторской_задолженности__дни': ' Период погашения кредиторской задолженности, дни',\n",
    "    '_Рентабельность_активов__ROA____': ' Рентабельность активов (ROA), %',\n",
    "    '_Рентабельность_затрат___': ' Рентабельность затрат, %',\n",
    "    '_Рентабельность_капитала__ROE____': ' Рентабельность капитала (ROE), %',\n",
    "    '_Рентабельность_продаж___': ' Рентабельность продаж, %',\n",
    "    '_Соотношение_чистого_долга_к_капиталу___': ' Соотношение чистого долга к капиталу, %'\n",
    "}\n",
    "\n",
    "# Create a new DataFrame with renamed columns from X_test\n",
    "# X_test_filtered = X_test[list(column_mapping.keys())] #!!! странное поведение датафрейма\n",
    "X_test_renamed = X_test.rename(columns=column_mapping)\n",
    "X_test_renamed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание датасета с всеми нужными столбцами для модели Альтмана\n",
    "# некоторые данные загружены из исходного датасета потому что в начале были удалены\n",
    "# далее проверки что мэтч произошёл бесшовно\n",
    "\n",
    "df = pd.read_parquet('data/data_cleaned.parquet')\n",
    "df['Год'] = pd.to_numeric(df['Год'], errors='coerce')\n",
    "\n",
    "columns_to_match = ['Год', '_Доля_рабочего_капитала_в_активах_компании___',\n",
    "                    '_Коэффициент_абсолютной_ликвидности___', '_Коэффициент_быстрой_ликвидности___',\n",
    "                    '_Коэффициент_обеспеченности_собственными_оборотными_средствами___',\n",
    "                    '_Коэффициент_оборачиваемости_совокупных_активов___',\n",
    "                    '_Коэффициент_соотношения_заемных_и_собственных_средств___',\n",
    "                    '_Коэффициент_текущей_ликвидности___', '_Период_оборота_активов__дни',\n",
    "                    '_Период_оборота_запасов__дни', '_Период_оборота_основных_средств__дни',\n",
    "                    '_Период_погашения_дебиторской_задолженности__дни',\n",
    "                    '_Период_погашения_кредиторской_задолженности__дни',\n",
    "                    '_Рентабельность_активов__ROA____', '_Рентабельность_затрат___',\n",
    "                    '_Рентабельность_капитала__ROE____', '_Рентабельность_продаж___',\n",
    "                    '_Соотношение_чистого_долга_к_капиталу___']\n",
    "\n",
    "# список колонок на мэтч написан старый, переименовали его по словарю\n",
    "columns_to_match = [column_mapping.get(col, col) for col in columns_to_match]\n",
    "\n",
    "# Соединение датафрейма по общим столбцам\n",
    "matched_df = pd.merge(X_test_renamed, df, on=columns_to_match, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test_renamed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matched_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_altman = matched_df.apply(altman_z_score, axis=1)\n",
    "preds_altman.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zxc = \"\"\n",
    "y_test = pd.read_parquet(f'data/y_test.parquet{zxc}')\n",
    "print(y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выбросы в датасете приводят к сильным выбросам модели альтмана, их нужно удалить\n",
    "\n",
    "invalid_indexes = preds_altman[(preds_altman < 0) | (preds_altman > 4)].index\n",
    "\n",
    "preds_altman_filtered = preds_altman.drop(invalid_indexes)\n",
    "y_test_filtered = y_test.drop(invalid_indexes, axis='index')\n",
    "\n",
    "preds_altman_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нормализованный предикт, от 0 до 1\n",
    "\n",
    "preds_altman_norm = (preds_altman_filtered - preds_altman_filtered.min()) / (preds_altman_filtered.max() - preds_altman_filtered.min())\n",
    "preds_altman_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ИНВЕРТИРУЕМ ТАК КАК У АЛЬТМАНА больше = стабильнее, а у нас больше = банкрот\n",
    "\n",
    "preds_altman_norm=1-preds_altman_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценка предикта простым округлением\n",
    "\n",
    "# ДЛЯ ПРИМЕРА, ДАЛЕЕ БОЛЕЕ ОБЪЕКТИВНАЯ ОЦЕНКА\n",
    "\n",
    "print(classification_report(y_test_filtered, [round(i) for i in preds_altman_norm]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценка предикта ROC AUC\n",
    "\n",
    "build_roc_curve(y_test_filtered, preds_altman_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценим как классификатор\n",
    "# но по сути это бессмысленно, просто так мы можем не удалять выбросы\n",
    "\n",
    "threshold = 1.81\n",
    "# (1.81+2.99)/2\n",
    "\n",
    "binary_preds_altman = preds_altman.apply(lambda x: 1 if x < threshold else 0)\n",
    "\n",
    "print(classification_report(y_test, binary_preds_altman))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробуем с параметрами для непубличных компаний\n",
    "\n",
    "preds_altman = matched_df.apply(altman_z_score, P = params_private, axis=1)\n",
    "\n",
    "invalid_indexes = preds_altman[(preds_altman < 0) | (preds_altman > 4)].index\n",
    "\n",
    "preds_altman_filtered = preds_altman.drop(invalid_indexes)\n",
    "y_test_filtered = y_test.drop(invalid_indexes)\n",
    "\n",
    "preds_altman_norm = (preds_altman_filtered - preds_altman_filtered.min()) / (preds_altman_filtered.max() - preds_altman_filtered.min())\n",
    "\n",
    "preds_altman_norm=1-preds_altman_norm\n",
    "\n",
    "print(classification_report(y_test_filtered, [round(i) for i in preds_altman_norm]))\n",
    "build_roc_curve(y_test_filtered, preds_altman_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# модель Таффлера\n",
    "\n",
    "def taffler_score(row):\n",
    "    working_capital = row[' Собственный оборотный капитал, RUB']\n",
    "    total_assets = row[' Активы  всего, RUB']\n",
    "    retained_earnings = row[' Нераспределенная прибыль (непокрытый убыток), RUB']\n",
    "    ebit = row[' Выручка, RUB'] - row[' Себестоимость продаж, RUB']\n",
    "    total_liabilities = row[' Краткосрочные обязательства, RUB']\n",
    "    book_value_of_equity = total_assets - total_liabilities  # Приближенное значение\n",
    "\n",
    "    if total_assets == 0 or total_liabilities == 0:  # Избегаем деления на ноль\n",
    "        return pd.NA  # Возвращаем специальный NA тип данных pandas для отсутствующих данных\n",
    "\n",
    "    working_capital_to_assets = working_capital / total_assets\n",
    "    retained_earnings_to_assets = retained_earnings / total_assets\n",
    "    ebit_to_assets = ebit / total_assets\n",
    "    book_equity_to_liabilities = book_value_of_equity / total_liabilities\n",
    "\n",
    "    return (0.53 * working_capital_to_assets +\n",
    "            0.13 * retained_earnings_to_assets +\n",
    "            0.18 * ebit_to_assets +\n",
    "            0.16 * book_equity_to_liabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_taffler = matched_df.apply(taffler_score, axis=1)\n",
    "preds_taffler.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим метрики обычной классификации\n",
    "\n",
    "threshold = 0.25\n",
    "\n",
    "print(classification_report(y_test, [round(i) for i in preds_taffler.apply(lambda x: 1 if x < threshold else 0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# наоборот\n",
    "\n",
    "print(classification_report(y_test, [round(i) for i in preds_taffler.apply(lambda x: 0 if x < threshold else 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_indexes = preds_taffler[(preds_taffler < 0) | (preds_taffler > 0.35)].index\n",
    "\n",
    "preds_taffler_filtered = preds_taffler.drop(invalid_indexes)\n",
    "y_test_filtered = y_test.drop(invalid_indexes)\n",
    "\n",
    "preds_taffler_norm = (preds_taffler_filtered - preds_taffler_filtered.min()) / (preds_taffler_filtered.max() - preds_taffler_filtered.min())\n",
    "\n",
    "preds_taffler_norm=1-preds_taffler_norm\n",
    "\n",
    "# print(classification_report(y_test_filtered, [round(i) for i in preds_taffler_norm]))\n",
    "build_roc_curve(y_test_filtered, preds_taffler_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ДОРАБОТКА 666\n",
    "# baseline модель\n",
    "# что будет если объявить всех не банкротами\n",
    "\n",
    "y_pred_cringe = [0 for pred in y_test]\n",
    "calculate_classification_metrics(y_test, y_pred_cringe)\n",
    "build_roc_curve(y_test, y_pred_cringe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
